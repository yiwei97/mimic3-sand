{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ce6152-2484-4dd3-b29f-d5f79dacc3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current File Path: /home/jovyan/mimic3-sand/mimic3models/phenotyping\n",
      "Base Path: /home/jovyan/mimic3-sand\n"
     ]
    }
   ],
   "source": [
    "# Standard library\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "# Third-party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "cur_path = Path(\".\").resolve()\n",
    "base_path = cur_path.parents[1]\n",
    "\n",
    "print(f\"Current File Path: {cur_path}\")\n",
    "print(f\"Base Path: {base_path}\")\n",
    "\n",
    "os.chdir(str(base_path))\n",
    "sys.path.append(str(base_path))\n",
    "\n",
    "# Local modules\n",
    "from mimic3benchmark.readers import PhenotypingReader\n",
    "from mimic3models import common_utils\n",
    "from mimic3models.phenotyping import utils\n",
    "from mimic3models.preprocessing import Discretizer, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbedd523-9d91-4f4c-9eb9-7887e4975765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f70a6-cb53-422e-b5c4-ff98c9479c2f",
   "metadata": {},
   "source": [
    "# Arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f358ca7-3b0c-429b-a0d7-2db7cbef8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(n_positions: int, hidden_dim: int) -> torch.Tensor:\n",
    "    def calc_angles(pos, i):\n",
    "        rates = 1 / np.power(10000, (2*(i // 2)) / np.float32(hidden_dim))\n",
    "        return pos * rates\n",
    "\n",
    "    rads = calc_angles(np.arange(n_positions)[:, np.newaxis], np.arange(hidden_dim)[np.newaxis, :])\n",
    "\n",
    "    rads[:, 0::2] = np.sin(rads[:, 0::2])\n",
    "    rads[:, 1::2] = np.cos(rads[:, 1::2])\n",
    "\n",
    "    pos_enc = rads[np.newaxis, ...]\n",
    "    pos_enc = torch.tensor(pos_enc, dtype=torch.float32, requires_grad=False)\n",
    "    return pos_enc\n",
    "\n",
    "\n",
    "def dense_interpolation(batch_size: int, seq_len: int, factor: int) -> torch.Tensor:\n",
    "    W = np.zeros((factor, seq_len), dtype=np.float32)\n",
    "    for t in range(seq_len):\n",
    "        s = np.array((factor * (t + 1)) / seq_len, dtype=np.float32)\n",
    "        for m in range(factor):\n",
    "            tmp = np.array(1 - (np.abs(s - (1 + m)) / factor), dtype=np.float32)\n",
    "            w = np.power(tmp, 2, dtype=np.float32)\n",
    "            W[m, t] = w\n",
    "\n",
    "    W = torch.tensor(W, requires_grad=False).float().unsqueeze(0)\n",
    "    return W.repeat(batch_size, 1, 1)\n",
    "\n",
    "\n",
    "def subsequent_mask(size: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    from Harvard NLP\n",
    "    The Annotated Transformer\n",
    "\n",
    "    http://nlp.seas.harvard.edu/2018/04/03/attention.html#batches-and-masking\n",
    "\n",
    "    :param size: int\n",
    "    :return: torch.Tensor\n",
    "    \"\"\"\n",
    "    attn_shape = (size, size)\n",
    "    mask = np.triu(np.ones(attn_shape), k=1).astype(\"float32\")\n",
    "    mask = torch.from_numpy(mask) == 0\n",
    "    return mask.float()\n",
    "\n",
    "\n",
    "class ScheduledOptimizer:\n",
    "    \"\"\"\n",
    "    Reference: `jadore801120/attention-is-all-you-need-pytorch \\\n",
    "    <https://github.com/jadore801120/attention-is-all-you-need-pytorch/blob/master/transformer/Optim.py>`_\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, d_model: int, warm_up: int) -> None:\n",
    "        self._optimizer = optimizer\n",
    "        self.warm_up = warm_up\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self) -> np.array:\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.warm_up, -1.5) * self.n_current_steps\n",
    "        ])\n",
    "\n",
    "    def get_lr(self):\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "        return lr\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.get_lr()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "\n",
    "    def state_dict(self):\n",
    "        return self._optimizer.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afab52cb-3712-4329-8077-291c42825c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_len, device=device):\n",
    "    \"\"\"\n",
    "    Generates an upper triangular mask for causal attention.\n",
    "    \"\"\"\n",
    "    # Use torch.nn.Transformer.generate_square_subsequent_mask for compatibility\n",
    "    mask = nn.Transformer.generate_square_subsequent_mask(seq_len)\n",
    "    return mask.to(device)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, seq_len) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "\n",
    "        for pos in range(seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / d_model)))\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        seq_len = x.shape[1]\n",
    "        x = math.sqrt(self.d_model) * x\n",
    "        x = x + self.pe[:, :seq_len].requires_grad_(False)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, layer: nn.Module, embed_dim: int, seq_len, p=0.1) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer = layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.attn_weights = None\n",
    "        self.causal_mask = generate_causal_mask(seq_len, device=device)\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: [N, seq_len, features]\n",
    "        :return: [N, seq_len, features]\n",
    "        \"\"\"\n",
    "        if isinstance(self.layer, nn.MultiheadAttention):\n",
    "            src = x.transpose(0, 1)     # [seq_len, N, features]\n",
    "            output, self.attn_weights = self.layer(src, src, src, attn_mask=self.causal_mask, is_causal=True)\n",
    "            output = output.transpose(0, 1)     # [N, seq_len, features]\n",
    "\n",
    "        else:\n",
    "            output = self.layer(x)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        output = self.norm(x + output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size: int) -> None:\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(hidden_size, hidden_size * 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size * 2, hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        tensor = tensor.transpose(1, 2)\n",
    "        tensor = self.conv(tensor)\n",
    "        tensor = tensor.transpose(1, 2)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_head: int, seq_len, dropout_rate=0.1) -> None:\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = ResidualBlock(\n",
    "            nn.MultiheadAttention(embed_dim, num_head), embed_dim, seq_len, p=dropout_rate\n",
    "        )\n",
    "        self.ffn = ResidualBlock(PositionWiseFeedForward(embed_dim), embed_dim, seq_len, p=dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseInterpolation(nn.Module):\n",
    "    def __init__(self, seq_len: int, factor: int) -> None:\n",
    "        \"\"\"\n",
    "        :param seq_len: sequence length\n",
    "        :param factor: factor M\n",
    "        \"\"\"\n",
    "        super(DenseInterpolation, self).__init__()\n",
    "\n",
    "        W = np.zeros((factor, seq_len), dtype=np.float32)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            s = np.array((factor * (t + 1)) / seq_len, dtype=np.float32)\n",
    "            for m in range(factor):\n",
    "                tmp = np.array(1 - (np.abs(s - (1+m)) / factor), dtype=np.float32)\n",
    "                w = np.power(tmp, 2, dtype=np.float32)\n",
    "                W[m, t] = w\n",
    "\n",
    "        W = torch.tensor(W).float().unsqueeze(0)\n",
    "        self.register_buffer(\"W\", W)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        w = self.W.repeat(x.shape[0], 1, 1).requires_grad_(False)\n",
    "        u = torch.bmm(w, x)\n",
    "        return u.transpose_(1, 2)\n",
    "\n",
    "\n",
    "class ClassificationModule(nn.Module):\n",
    "    def __init__(self, d_model: int, factor: int, num_class: int) -> None:\n",
    "        super(ClassificationModule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.factor = factor\n",
    "        self.num_class = num_class\n",
    "\n",
    "        self.fc = nn.Linear(int(d_model * factor), num_class)\n",
    "\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.contiguous().view(-1, int(self.factor * self.d_model))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RegressionModule(nn.Module):\n",
    "    def __init__(self, d_model: int, factor: int, output_size: int) -> None:\n",
    "        super(RegressionModule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.factor = factor\n",
    "        self.output_size = output_size\n",
    "        self.fc = nn.Linear(int(d_model * factor), output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.contiguous().view(-1, int(self.factor * self.d_model))\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5869a166-88e9-4b03-b20f-76a005a50bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_len, device=device):\n",
    "    \"\"\"\n",
    "    Generates an upper triangular mask for causal attention.\n",
    "    \"\"\"\n",
    "    # Use torch.nn.Transformer.generate_square_subsequent_mask for compatibility\n",
    "    mask = nn.Transformer.generate_square_subsequent_mask(seq_len)\n",
    "    return mask.to(device)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, seq_len) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "\n",
    "        for pos in range(seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000 ** ((2 * (i+1)) / d_model)))\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        seq_len = x.shape[1]\n",
    "        x = math.sqrt(self.d_model) * x\n",
    "        x = x + self.pe[:, :seq_len].requires_grad_(False)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, layer: nn.Module, embed_dim: int, seq_len, p=0.1) -> None:\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.layer = layer\n",
    "        self.dropout = nn.Dropout(p=p)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.attn_weights = None\n",
    "        self.causal_mask = generate_causal_mask(seq_len, device=device)\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: [N, seq_len, features]\n",
    "        :return: [N, seq_len, features]\n",
    "        \"\"\"\n",
    "        if isinstance(self.layer, nn.MultiheadAttention):\n",
    "            src = x.transpose(0, 1)     # [seq_len, N, features]\n",
    "            output, self.attn_weights = self.layer(src, src, src, attn_mask=self.causal_mask, is_causal=True)\n",
    "            output = output.transpose(0, 1)     # [N, seq_len, features]\n",
    "\n",
    "        else:\n",
    "            output = self.layer(x)\n",
    "\n",
    "        output = self.dropout(output)\n",
    "        output = self.norm(x + output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, hidden_size: int) -> None:\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(hidden_size, hidden_size * 2, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size * 2, hidden_size, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        tensor = tensor.transpose(1, 2)\n",
    "        tensor = self.conv(tensor)\n",
    "        tensor = tensor.transpose(1, 2)\n",
    "\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_head: int, seq_len, dropout_rate=0.1) -> None:\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.attention = ResidualBlock(\n",
    "            nn.MultiheadAttention(embed_dim, num_head), embed_dim, seq_len, p=dropout_rate\n",
    "        )\n",
    "        self.ffn = ResidualBlock(PositionWiseFeedForward(embed_dim), embed_dim, seq_len, p=dropout_rate)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.attention(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DenseInterpolation(nn.Module):\n",
    "    def __init__(self, seq_len: int, factor: int) -> None:\n",
    "        \"\"\"\n",
    "        :param seq_len: sequence length\n",
    "        :param factor: factor M\n",
    "        \"\"\"\n",
    "        super(DenseInterpolation, self).__init__()\n",
    "\n",
    "        W = np.zeros((factor, seq_len), dtype=np.float32)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            s = np.array((factor * (t + 1)) / seq_len, dtype=np.float32)\n",
    "            for m in range(factor):\n",
    "                tmp = np.array(1 - (np.abs(s - (1+m)) / factor), dtype=np.float32)\n",
    "                w = np.power(tmp, 2, dtype=np.float32)\n",
    "                W[m, t] = w\n",
    "\n",
    "        W = torch.tensor(W).float().unsqueeze(0)\n",
    "        self.register_buffer(\"W\", W)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        w = self.W.repeat(x.shape[0], 1, 1).requires_grad_(False)\n",
    "        u = torch.bmm(w, x)\n",
    "        return u.transpose_(1, 2)\n",
    "\n",
    "\n",
    "class ClassificationModule(nn.Module):\n",
    "    def __init__(self, d_model: int, factor: int, num_class: int) -> None:\n",
    "        super(ClassificationModule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.factor = factor\n",
    "        self.num_class = num_class\n",
    "\n",
    "        self.fc = nn.Linear(int(d_model * factor), num_class)\n",
    "\n",
    "        nn.init.normal_(self.fc.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.contiguous().view(-1, int(self.factor * self.d_model))\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RegressionModule(nn.Module):\n",
    "    def __init__(self, d_model: int, factor: int, output_size: int) -> None:\n",
    "        super(RegressionModule, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.factor = factor\n",
    "        self.output_size = output_size\n",
    "        self.fc = nn.Linear(int(d_model * factor), output_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.contiguous().view(-1, int(self.factor * self.d_model))\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2140e681-eafc-4027-87d4-56f21082ef41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayerForSAnD(nn.Module):\n",
    "    def __init__(self, input_features, seq_len, n_heads, n_layers, d_model=128, dropout_rate=0.2) -> None:\n",
    "        super(EncoderLayerForSAnD, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.input_embedding = nn.Conv1d(input_features, d_model, 1)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, seq_len)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            EncoderBlock(d_model, n_heads, seq_len, dropout_rate) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.input_embedding(x)\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        for l in self.blocks:\n",
    "            x = l(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SAnD(nn.Module):\n",
    "    \"\"\"\n",
    "    Simply Attend and Diagnose model\n",
    "\n",
    "    The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)\n",
    "\n",
    "    `Attend and Diagnose: Clinical Time Series Analysis Using Attention Models <https://arxiv.org/abs/1711.03905>`_\n",
    "    Huan Song, Deepta Rajan, Jayaraman J. Thiagarajan, Andreas Spanias\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, input_features: int, seq_len: int, n_heads: int, factor: int,\n",
    "            n_class: int, n_layers: int, d_model: int = 128, dropout_rate: float = 0.2\n",
    "    ) -> None:\n",
    "        super(SAnD, self).__init__()\n",
    "        self.encoder = EncoderLayerForSAnD(input_features, seq_len, n_heads, n_layers, d_model, dropout_rate)\n",
    "        self.dense_interpolation = DenseInterpolation(seq_len, factor)\n",
    "        self.clf = ClassificationModule(d_model, factor, n_class)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoder(x)\n",
    "        x = self.dense_interpolation(x)\n",
    "        x = self.clf(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "887a1c9a-b565-4f26-999b-b15b44911d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkClassifier:\n",
    "    \"\"\"\n",
    "    | NeuralNetworkClassifier depend on `Comet-ML <https://www.comet.ml/>`_ .\n",
    "    | You have to create a project on your workspace of Comet, if you use this class.\n",
    "    |\n",
    "    | example\n",
    "\n",
    "    ---------------------\n",
    "    1st, Write your code.\n",
    "    ---------------------\n",
    "    ::\n",
    "\n",
    "        # code.py\n",
    "        from comet_ml import Experiment\n",
    "        import torch\n",
    "        import torch.nn as nn\n",
    "        import torch.optim as optim\n",
    "        from SAnD.utils.trainer import NeuralNetworkClassifier\n",
    "\n",
    "        class Network(nn.Module):\n",
    "           def __init__(self):\n",
    "               super(Network ,self).__init__()\n",
    "               ...\n",
    "           def forward(self, x):\n",
    "               ...\n",
    "\n",
    "        optimizer_config = {\"lr\": 0.001, \"betas\": (0.9, 0.999), \"eps\": 1e-08}\n",
    "        comet_config = {}\n",
    "\n",
    "        train_val_loader = {\n",
    "           \"train\": train_loader,\n",
    "           \"val\": val_loader\n",
    "        }\n",
    "        test_loader = DataLoader(test_ds, batch_size)\n",
    "\n",
    "        clf = NeuralNetworkClassifier(\n",
    "                Network(), nn.CrossEntropyLoss(),\n",
    "                optim.Adam, optimizer_config, Experiment()\n",
    "            )\n",
    "\n",
    "        clf.experiment_tag = \"experiment_tag\"\n",
    "        clf.num_classes = 3\n",
    "        clf.fit(train_val_loader, epochs=10)\n",
    "        clf.evaluate(test_loader)\n",
    "        lf.confusion_matrix(test_ds)\n",
    "        clf.save_weights(\"save_params_test/\")\n",
    "\n",
    "    ----------------------------\n",
    "    2nd, Run code on your shell.\n",
    "    ----------------------------\n",
    "    | You need to define 2 environment variables.\n",
    "    | :code:`COMET_API_KEY` & :code:`COMET_PROJECT_NAME`\n",
    "\n",
    "    On Unix-like system, you can define them like this and execute code.\n",
    "    ::\n",
    "\n",
    "        export COMET_API_KEY=\"YOUR-API-KEY\"\n",
    "        export COMET_PROJECT_NAME=\"YOUR-PROJECT-NAME\"\n",
    "        user@user$ python code.py\n",
    "\n",
    "    -------------------------------------------\n",
    "    3rd, check logs on your workspace of comet.\n",
    "    -------------------------------------------\n",
    "    Just access your `Comet-ML <https://www.comet.ml/>`_ Project page.\n",
    "\n",
    "    ^^^^^\n",
    "    Note,\n",
    "    ^^^^^\n",
    "\n",
    "    Execute this command on your shell, ::\n",
    "\n",
    "        export COMET_DISABLE_AUTO_LOGGING=1\n",
    "\n",
    "    If the following error occurs. ::\n",
    "\n",
    "        ImportError: You must import Comet before these modules: torch\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model, criterion, optimizer, optimizer_config: dict, experiment) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "        self.optimizer = optimizer(self.model.parameters(), **optimizer_config)\n",
    "        self.criterion = criterion\n",
    "        # self.experiment = experiment\n",
    "\n",
    "        self.hyper_params = optimizer_config\n",
    "        self._start_epoch = 0\n",
    "        self.hyper_params[\"epochs\"] = self._start_epoch\n",
    "        self.__num_classes = None\n",
    "        self._is_parallel = False\n",
    "        \n",
    "        self.run = wandb.init(\n",
    "            project='sand-mimic3',\n",
    "            config={\n",
    "                \"task\" : \"in-hospital-mortality\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "            self._is_parallel = True\n",
    "\n",
    "            notice = \"Running on {} GPUs.\".format(torch.cuda.device_count())\n",
    "            print(\"\\033[33m\" + notice + \"\\033[0m\")\n",
    "            \n",
    "            \n",
    "\n",
    "    def fit(self, loader: Dict[str, DataLoader], epochs: int, checkpoint_path: str = None, validation: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        | The method of training your PyTorch Model.\n",
    "        | With the assumption, This method use for training network for classification.\n",
    "\n",
    "        ::\n",
    "\n",
    "            train_ds = Subset(train_val_ds, train_index)\n",
    "            val_ds = Subset(train_val_ds, val_index)\n",
    "\n",
    "            train_val_loader = {\n",
    "                \"train\": DataLoader(train_ds, batch_size),\n",
    "                \"val\": DataLoader(val_ds, batch_size)\n",
    "            }\n",
    "\n",
    "            clf = NeuralNetworkClassifier(\n",
    "                    Network(), nn.CrossEntropyLoss(),\n",
    "                    optim.Adam, optimizer_config, experiment\n",
    "                )\n",
    "            clf.fit(train_val_loader, epochs=10)\n",
    "\n",
    "\n",
    "        :param loader: Dictionary which contains Data Loaders for training and validation.: dict{DataLoader, DataLoader}\n",
    "        :param epochs: The number of epochs: int\n",
    "        :param checkpoint_path: str\n",
    "        :param validation:\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "\n",
    "        len_of_train_dataset = len(loader[\"train\"].dataset)\n",
    "        epochs = epochs + self._start_epoch\n",
    "\n",
    "        self.hyper_params[\"epochs\"] = epochs\n",
    "        self.hyper_params[\"batch_size\"] = loader[\"train\"].batch_size\n",
    "        self.hyper_params[\"train_ds_size\"] = len_of_train_dataset\n",
    "\n",
    "        if validation:\n",
    "            len_of_val_dataset = len(loader[\"val\"].dataset)\n",
    "            self.hyper_params[\"val_ds_size\"] = len_of_val_dataset\n",
    "\n",
    "        # self.experiment.log_parameters(self.hyper_params)\n",
    "\n",
    "        for epoch in range(self._start_epoch, epochs):\n",
    "            if checkpoint_path is not None and epoch % 100 == 0:\n",
    "                self.save_to_file(checkpoint_path)\n",
    "            # with self.experiment.train():\n",
    "            if True:\n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "\n",
    "                self.model.train()\n",
    "                pbar = tqdm.tqdm(total=len_of_train_dataset)\n",
    "                total_loss = 0\n",
    "                for x, y in loader[\"train\"]:\n",
    "                    b_size = y.shape[0]\n",
    "                    total += y.shape[0]\n",
    "                    x = x.to(self.device) if isinstance(x, torch.Tensor) else [i.to(self.device) for i in x]\n",
    "                    y = y.to(self.device)\n",
    "\n",
    "                    pbar.set_description(\n",
    "                        \"\\033[36m\" + \"Training\" + \"\\033[0m\" + \" - Epochs: {:03d}/{:03d}\".format(epoch+1, epochs)\n",
    "                    )\n",
    "                    pbar.update(b_size)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    outputs = self.model(x)\n",
    "                    loss = self.criterion(outputs, y)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    correct += (predicted == y).sum().float().cpu().item()\n",
    "\n",
    "                    total_loss += loss.cpu().item()\n",
    "                \n",
    "                total_loss = total_loss / len(loader['train'])\n",
    "                \n",
    "                    \n",
    "            if validation:\n",
    "                # with self.experiment.validate():\n",
    "                if True:\n",
    "                    with torch.no_grad():\n",
    "                        val_correct = 0.0\n",
    "                        val_total = 0.0\n",
    "\n",
    "                        self.model.eval()\n",
    "                        val_total_loss = 0\n",
    "                        for x_val, y_val in loader[\"val\"]:\n",
    "                            val_total += y_val.shape[0]\n",
    "                            x_val = x_val.to(self.device) if isinstance(x_val, torch.Tensor) else [i_val.to(self.device) for i_val in x_val]\n",
    "                            y_val = y_val.to(self.device)\n",
    "\n",
    "                            val_output = self.model(x_val)\n",
    "                            val_loss = self.criterion(val_output, y_val)\n",
    "                            _, val_pred = torch.max(val_output, 1)\n",
    "                            val_correct += (val_pred == y_val).sum().float().cpu().item()\n",
    "\n",
    "                            val_total_loss += val_loss.cpu().item()\n",
    "\n",
    "                        val_total_loss = val_total_loss / len(loader['val'])\n",
    "            \n",
    "            if validation:\n",
    "                self.run.log({'train_loss' : total_loss, 'train_accuracy' : float(correct / total), 'val_loss' : total_loss, 'val_accuracy' : float(val_correct / val_total)})\n",
    "            else:\n",
    "                self.run.log({'train_loss' : total_loss, 'train_accuracy' : float(correct / total)})\n",
    "\n",
    "            pbar.close()\n",
    "\n",
    "    def save_checkpoint(self) -> dict:\n",
    "        \"\"\"\n",
    "        The method of saving trained PyTorch model.\n",
    "\n",
    "        Note,  return value contains\n",
    "            - the number of last epoch as `epochs`\n",
    "            - optimizer state as `optimizer_state_dict`\n",
    "            - model state as `model_state_dict`\n",
    "\n",
    "        ::\n",
    "\n",
    "            clf = NeuralNetworkClassifier(\n",
    "                    Network(), nn.CrossEntropyLoss(),\n",
    "                    optim.Adam, optimizer_config, experiment\n",
    "                )\n",
    "\n",
    "            clf.fit(train_loader, epochs=10)\n",
    "            checkpoints = clf.save_checkpoint()\n",
    "\n",
    "        :return: dict {'epoch', 'optimizer_state_dict', 'model_state_dict'}\n",
    "        \"\"\"\n",
    "\n",
    "        checkpoints = {\n",
    "            \"epoch\": deepcopy(self.hyper_params[\"epochs\"]),\n",
    "            \"optimizer_state_dict\": deepcopy(self.optimizer.state_dict())\n",
    "        }\n",
    "\n",
    "        if self._is_parallel:\n",
    "            checkpoints[\"model_state_dict\"] = deepcopy(self.model.module.state_dict())\n",
    "        else:\n",
    "            checkpoints[\"model_state_dict\"] = deepcopy(self.model.state_dict())\n",
    "\n",
    "        return checkpoints\n",
    "\n",
    "    def save_to_file(self, path: str) -> str:\n",
    "        \"\"\"\n",
    "        | The method of saving trained PyTorch model to file.\n",
    "        | Those weights are uploaded to comet.ml as backup.\n",
    "        | check \"Asserts\".\n",
    "\n",
    "        Note, .pth file contains\n",
    "            - the number of last epoch as `epochs`\n",
    "            - optimizer state as `optimizer_state_dict`\n",
    "            - model state as `model_state_dict`\n",
    "\n",
    "        ::\n",
    "\n",
    "            clf = NeuralNetworkClassifier(\n",
    "                    Network(), nn.CrossEntropyLoss(),\n",
    "                    optim.Adam, optimizer_config, experiment\n",
    "                )\n",
    "\n",
    "            clf.fit(train_loader, epochs=10)\n",
    "            filename = clf.save_to_file('path/to/save/dir/')\n",
    "\n",
    "        :param path: path to saving directory. : string\n",
    "        :return: path to file : string\n",
    "        \"\"\"\n",
    "        if not os.path.isdir(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "        file_name = \"model_params-epochs_{}-{}.pth\".format(\n",
    "            self.hyper_params[\"epochs\"], time.ctime().replace(\" \", \"_\")\n",
    "        )\n",
    "        path = path + file_name\n",
    "\n",
    "        checkpoints = self.save_checkpoint()\n",
    "\n",
    "        torch.save(checkpoints, path)\n",
    "        # self.experiment.log_asset(path, file_name=file_name)\n",
    "\n",
    "        return path\n",
    "\n",
    "    def restore_checkpoint(self, checkpoints: dict) -> None:\n",
    "        \"\"\"\n",
    "        The method of loading trained PyTorch model.\n",
    "\n",
    "        :param checkpoints: dictionary which contains {'epoch', 'optimizer_state_dict', 'model_state_dict'}\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self._start_epoch = checkpoints[\"epoch\"]\n",
    "        if not isinstance(self._start_epoch, int):\n",
    "            raise TypeError\n",
    "\n",
    "        if self._is_parallel:\n",
    "            self.model.module.load_state_dict(checkpoints[\"model_state_dict\"])\n",
    "        else:\n",
    "            self.model.load_state_dict(checkpoints[\"model_state_dict\"])\n",
    "\n",
    "        self.optimizer.load_state_dict(checkpoints[\"optimizer_state_dict\"])\n",
    "\n",
    "    def restore_from_file(self, path: str, map_location: str = \"cpu\") -> None:\n",
    "        \"\"\"\n",
    "        The method of loading trained PyTorch model from file.\n",
    "\n",
    "        ::\n",
    "\n",
    "            clf = NeuralNetworkClassifier(\n",
    "                    Network(), nn.CrossEntropyLoss(),\n",
    "                    optim.Adam, optimizer_config, experiment\n",
    "                )\n",
    "            clf.restore_from_file('path/to/trained/weights.pth')\n",
    "\n",
    "        :param path: path to saved directory. : str\n",
    "        :param map_location: default cpu: str\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        checkpoints = torch.load(path, map_location=map_location)\n",
    "        self.restore_checkpoint(checkpoints)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920fbcca-6165-4319-bff3-3956ac746491",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d4a2095-3cc3-47db-aa16-b0e93ef14b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args Values (Hardcoded)\n",
    "data_dir = \"/search-data/evan/data/phenotyping/\" # input Your Data Dir Here Pointing To /in-hospital-mortality\n",
    "timestep = 1.0\n",
    "normalizer_state = None\n",
    "imputation = 'previous'\n",
    "\n",
    "train_reader = PhenotypingReader(\n",
    "    dataset_dir=os.path.join(data_dir, 'train'),\n",
    "    listfile=os.path.join(data_dir, 'train_listfile.csv'),\n",
    ")\n",
    "\n",
    "val_reader = PhenotypingReader(\n",
    "    dataset_dir=os.path.join(data_dir, 'train'),\n",
    "    listfile=os.path.join(data_dir, 'val_listfile.csv'),\n",
    ")\n",
    "\n",
    "discretizer = Discretizer(\n",
    "    timestep=float(timestep),\n",
    "    store_masks=True,\n",
    "    impute_strategy='previous',\n",
    "    start_time='zero'\n",
    ")\n",
    "\n",
    "discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
    "cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
    "\n",
    "normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n",
    "normalizer_state = normalizer_state\n",
    "if normalizer_state is None:\n",
    "    normalizer_state = 'ph_ts{}.input_str-previous.start_time-zero.normalizer'.format(timestep)\n",
    "    normalizer_state = os.path.join(cur_path, normalizer_state)\n",
    "normalizer.load_params(normalizer_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fb48e2-30f8-41a9-8f5c-a97285e83c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(reader, discretizer, normalizer, max_len, small_part=False):\n",
    "    N = reader.get_number_of_examples()\n",
    "    if small_part:\n",
    "        N = 1000\n",
    "\n",
    "    ret = common_utils.read_chunk(reader, N)\n",
    "    data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    ys = ret[\"y\"]\n",
    "    names = ret[\"name\"]\n",
    "\n",
    "    # Apply discretizer and normalizer\n",
    "    data = [discretizer.transform(X, end=t)[0] for (X, t) in zip(data, ts)]\n",
    "    if normalizer is not None:\n",
    "        data = [normalizer.transform(X) for X in data]\n",
    "\n",
    "    # Pad sequences so they all have the same length\n",
    "    in_feat = data[0].shape[1]\n",
    "    data_padded = np.zeros((len(data), max_len, in_feat), dtype=np.float32)\n",
    "    for i, x in enumerate(data):\n",
    "        data_padded[i, :x.shape[0], :] = x[-max_len:].astype(np.float32)\n",
    "\n",
    "    # Convert labels to array\n",
    "    ys = np.array(ys, dtype=np.int32)\n",
    "    ys_int = np.argmax(ys, axis=1)\n",
    "\n",
    "    return (data_padded, ys_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408f7408-fa98-4069-b9e5-553bcec7902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_part = False\n",
    "\n",
    "train_raw = load_data(train_reader, discretizer, normalizer, seq_len=300, small_part=small_part)\n",
    "val_raw = load_data(val_reader, discretizer, normalizer, seq_len=300, small_part=small_part)\n",
    "\n",
    "train_x, train_y = train_raw\n",
    "val_x, val_y = val_raw\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "val_y = np.array(val_y)\n",
    "\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.long)  # classification labels\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.long)\n",
    "\n",
    "\n",
    "train_ds = TensorDataset(train_x, train_y)\n",
    "val_ds = TensorDataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b233a-3377-4049-8132-5581468c90dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "088aee3c-fd26-4005-9b5d-135611eab593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "in_feature = 76\n",
    "seq_len = 300\n",
    "n_heads = 8 # Number of heads for multi-head attention layer: Should be fixed at 8\n",
    "factor = 120 # Dense interpolation factor (M): This depends on the task at hand\n",
    "num_class = 25 # Number of output class\n",
    "num_layers = 2 # Number of multi-head attention layers (N): This depends on the task at hand\n",
    "d_model = 32 # Original 256\n",
    "dropout_rate = 0.4\n",
    "mode = 'multiclass'\n",
    "optimizer = 'adam'\n",
    "optimizer_config = {\n",
    "    'lr' : 0.0005,\n",
    "    'betas' : (0.9, 0.98),\n",
    "    'eps' : 1e-08,\n",
    "}\n",
    "num_epochs = 10\n",
    "batch_size = 8 # Original 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef57617-11fa-4363-a6a8-40f926f5c706",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5535f4a-8fce-4764-bd4f-2fec63272f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmillikanevan\u001b[0m (\u001b[33mmillikanevan-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/mimic3-sand/wandb/run-20251115_142520-op17xkhm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/millikanevan-personal/sand-mimic3/runs/op17xkhm' target=\"_blank\">swept-terrain-30</a></strong> to <a href='https://wandb.ai/millikanevan-personal/sand-mimic3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/millikanevan-personal/sand-mimic3' target=\"_blank\">https://wandb.ai/millikanevan-personal/sand-mimic3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/millikanevan-personal/sand-mimic3/runs/op17xkhm' target=\"_blank\">https://wandb.ai/millikanevan-personal/sand-mimic3/runs/op17xkhm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = NeuralNetworkClassifier(\n",
    "    SAnD(in_feature, seq_len, n_heads, factor, num_class, num_layers, dropout_rate=dropout_rate),\n",
    "    nn.CrossEntropyLoss(),\n",
    "    optim.Adam,\n",
    "    optimizer_config=optimizer_config,\n",
    "    experiment=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0220ae81-f92f-471e-8e86-f0f866294b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    {\"train\": val_loader,\n",
    "     \"val\": val_loader},\n",
    "    epochs=20\n",
    ")\n",
    "model.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84886975-d404-4af5-a986-83b58d4060f5",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35b458db-c64c-4884-902a-0028aa34dd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reader = PhenotypingReader(\n",
    "    dataset_dir=os.path.join(data_dir, 'test'),\n",
    "    listfile=os.path.join(data_dir, 'test_listfile.csv')\n",
    ")\n",
    "test_raw = load_data(\n",
    "    test_reader, \n",
    "    discretizer, \n",
    "    normalizer, \n",
    "    max_len=seq_len,\n",
    "    small_part=small_part\n",
    ")\n",
    "\n",
    "test_x, test_y = test_raw\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.long)\n",
    "\n",
    "test_ds = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfb8a2e5-9563-464a-a411-4cc01dd6cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def evaluate_model_auc(model, dataloader, device=device, num_classes=25):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm.tqdm(dataloader, total=len(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(inputs)  # shape: [batch_size, num_classes]\n",
    "            probs = F.softmax(logits, dim=1)  # probabilities for all classes\n",
    "\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_probs.append(probs.cpu())\n",
    "\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_probs = torch.cat(all_probs).numpy()\n",
    "\n",
    "\n",
    "    # Multi-class classification\n",
    "    all_labels_bin = label_binarize(all_labels, classes=list(range(num_classes)))\n",
    "    auc_micro = roc_auc_score(all_labels_bin, all_probs, average='micro', multi_class='ovr')\n",
    "    auc_macro = roc_auc_score(all_labels_bin, all_probs, average='macro', multi_class='ovr')\n",
    "    auc_weighted = roc_auc_score(all_labels_bin, all_probs, average='weighted', multi_class='ovr')\n",
    "    return {\n",
    "        \"AUROC_micro\": auc_micro,\n",
    "        \"AUROC_macro\": auc_macro,\n",
    "        \"AUROC_weighted\": auc_weighted\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddcbd4a2-a613-4dd2-a42f-2012e723f0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/786 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 3/786 [00:00<00:29, 26.76it/s]\u001b[A\n",
      "  1%|          | 6/786 [00:00<00:29, 26.45it/s]\u001b[A\n",
      "  1%|          | 9/786 [00:00<00:29, 26.39it/s]\u001b[A\n",
      "  2%|▏         | 12/786 [00:00<00:29, 26.41it/s]\u001b[A\n",
      "  2%|▏         | 15/786 [00:00<00:33, 22.90it/s]\u001b[A\n",
      "  2%|▏         | 18/786 [00:00<00:31, 24.11it/s]\u001b[A\n",
      "  3%|▎         | 21/786 [00:00<00:30, 24.97it/s]\u001b[A\n",
      "  3%|▎         | 24/786 [00:00<00:29, 25.51it/s]\u001b[A\n",
      "  3%|▎         | 27/786 [00:01<00:33, 22.69it/s]\u001b[A\n",
      "  4%|▍         | 30/786 [00:01<00:31, 23.78it/s]\u001b[A\n",
      "  4%|▍         | 33/786 [00:01<00:30, 24.62it/s]\u001b[A\n",
      "  5%|▍         | 36/786 [00:01<00:29, 25.29it/s]\u001b[A\n",
      "  5%|▍         | 39/786 [00:01<00:32, 22.71it/s]\u001b[A\n",
      "  5%|▌         | 42/786 [00:01<00:31, 23.86it/s]\u001b[A\n",
      "  6%|▌         | 45/786 [00:01<00:29, 24.73it/s]\u001b[A\n",
      "  6%|▌         | 48/786 [00:01<00:29, 25.33it/s]\u001b[A\n",
      "  6%|▋         | 51/786 [00:02<00:32, 22.73it/s]\u001b[A\n",
      "  7%|▋         | 54/786 [00:02<00:30, 23.77it/s]\u001b[A\n",
      "  7%|▋         | 57/786 [00:02<00:29, 24.57it/s]\u001b[A\n",
      "  8%|▊         | 60/786 [00:02<00:28, 25.14it/s]\u001b[A\n",
      "  8%|▊         | 63/786 [00:02<00:31, 22.60it/s]\u001b[A\n",
      "  8%|▊         | 66/786 [00:02<00:30, 23.67it/s]\u001b[A\n",
      "  9%|▉         | 69/786 [00:02<00:29, 24.53it/s]\u001b[A\n",
      "  9%|▉         | 72/786 [00:02<00:28, 25.10it/s]\u001b[A\n",
      " 10%|▉         | 75/786 [00:03<00:31, 22.53it/s]\u001b[A\n",
      " 10%|▉         | 78/786 [00:03<00:30, 23.58it/s]\u001b[A\n",
      " 10%|█         | 81/786 [00:03<00:28, 24.39it/s]\u001b[A\n",
      " 11%|█         | 84/786 [00:03<00:31, 22.12it/s]\u001b[A\n",
      " 11%|█         | 87/786 [00:03<00:29, 23.31it/s]\u001b[A\n",
      " 11%|█▏        | 90/786 [00:03<00:28, 24.09it/s]\u001b[A\n",
      " 12%|█▏        | 93/786 [00:03<00:28, 24.69it/s]\u001b[A\n",
      " 12%|█▏        | 96/786 [00:04<00:30, 22.30it/s]\u001b[A\n",
      " 13%|█▎        | 99/786 [00:04<00:29, 23.35it/s]\u001b[A\n",
      " 13%|█▎        | 102/786 [00:04<00:28, 24.15it/s]\u001b[A\n",
      " 13%|█▎        | 105/786 [00:04<00:31, 21.94it/s]\u001b[A\n",
      " 14%|█▎        | 108/786 [00:04<00:29, 23.15it/s]\u001b[A\n",
      " 14%|█▍        | 111/786 [00:04<00:28, 23.77it/s]\u001b[A\n",
      " 15%|█▍        | 114/786 [00:04<00:31, 21.26it/s]\u001b[A\n",
      " 15%|█▍        | 117/786 [00:04<00:29, 22.31it/s]\u001b[A\n",
      " 15%|█▌        | 120/786 [00:05<00:32, 20.39it/s]\u001b[A\n",
      " 16%|█▌        | 123/786 [00:05<00:30, 21.53it/s]\u001b[A\n",
      " 16%|█▌        | 126/786 [00:05<00:33, 19.91it/s]\u001b[A\n",
      " 16%|█▋        | 129/786 [00:05<00:31, 21.09it/s]\u001b[A\n",
      " 17%|█▋        | 132/786 [00:05<00:29, 22.41it/s]\u001b[A\n",
      " 17%|█▋        | 135/786 [00:05<00:31, 20.93it/s]\u001b[A\n",
      " 18%|█▊        | 138/786 [00:05<00:29, 22.25it/s]\u001b[A\n",
      " 18%|█▊        | 141/786 [00:06<00:27, 23.36it/s]\u001b[A\n",
      " 18%|█▊        | 144/786 [00:06<00:29, 21.44it/s]\u001b[A\n",
      " 19%|█▊        | 147/786 [00:06<00:28, 22.66it/s]\u001b[A\n",
      " 19%|█▉        | 150/786 [00:06<00:26, 23.71it/s]\u001b[A\n",
      " 19%|█▉        | 153/786 [00:06<00:25, 24.52it/s]\u001b[A\n",
      " 20%|█▉        | 156/786 [00:06<00:28, 21.95it/s]\u001b[A\n",
      " 20%|██        | 159/786 [00:06<00:27, 22.47it/s]\u001b[A\n",
      " 21%|██        | 162/786 [00:07<00:30, 20.71it/s]\u001b[A\n",
      " 21%|██        | 165/786 [00:07<00:28, 21.98it/s]\u001b[A\n",
      " 21%|██▏       | 168/786 [00:07<00:27, 22.87it/s]\u001b[A\n",
      " 22%|██▏       | 171/786 [00:07<00:29, 20.98it/s]\u001b[A\n",
      " 22%|██▏       | 174/786 [00:07<00:27, 22.17it/s]\u001b[A\n",
      " 23%|██▎       | 177/786 [00:07<00:29, 20.64it/s]\u001b[A\n",
      " 23%|██▎       | 180/786 [00:07<00:27, 21.94it/s]\u001b[A\n",
      " 23%|██▎       | 183/786 [00:07<00:26, 22.92it/s]\u001b[A\n",
      " 24%|██▎       | 186/786 [00:08<00:28, 21.11it/s]\u001b[A\n",
      " 24%|██▍       | 189/786 [00:08<00:26, 22.31it/s]\u001b[A\n",
      " 24%|██▍       | 192/786 [00:08<00:25, 23.16it/s]\u001b[A\n",
      " 25%|██▍       | 195/786 [00:08<00:27, 21.13it/s]\u001b[A\n",
      " 25%|██▌       | 198/786 [00:08<00:26, 22.26it/s]\u001b[A\n",
      " 26%|██▌       | 201/786 [00:08<00:25, 23.16it/s]\u001b[A\n",
      " 26%|██▌       | 204/786 [00:08<00:27, 21.17it/s]\u001b[A\n",
      " 26%|██▋       | 207/786 [00:09<00:25, 22.33it/s]\u001b[A\n",
      " 27%|██▋       | 210/786 [00:09<00:27, 20.68it/s]\u001b[A\n",
      " 27%|██▋       | 213/786 [00:09<00:26, 21.90it/s]\u001b[A\n",
      " 27%|██▋       | 216/786 [00:09<00:24, 22.88it/s]\u001b[A\n",
      " 28%|██▊       | 219/786 [00:09<00:26, 21.03it/s]\u001b[A\n",
      " 28%|██▊       | 222/786 [00:09<00:25, 22.20it/s]\u001b[A\n",
      " 29%|██▊       | 225/786 [00:09<00:24, 23.09it/s]\u001b[A\n",
      " 29%|██▉       | 228/786 [00:10<00:26, 21.14it/s]\u001b[A\n",
      " 29%|██▉       | 231/786 [00:10<00:24, 22.20it/s]\u001b[A\n",
      " 30%|██▉       | 234/786 [00:10<00:26, 20.58it/s]\u001b[A\n",
      " 30%|███       | 237/786 [00:10<00:25, 21.73it/s]\u001b[A\n",
      " 31%|███       | 240/786 [00:10<00:24, 22.68it/s]\u001b[A\n",
      " 31%|███       | 243/786 [00:10<00:26, 20.61it/s]\u001b[A\n",
      " 31%|███▏      | 246/786 [00:10<00:24, 21.70it/s]\u001b[A\n",
      " 32%|███▏      | 249/786 [00:11<00:26, 19.97it/s]\u001b[A\n",
      " 32%|███▏      | 252/786 [00:11<00:25, 21.14it/s]\u001b[A\n",
      " 32%|███▏      | 255/786 [00:11<00:27, 19.63it/s]\u001b[A\n",
      " 33%|███▎      | 258/786 [00:11<00:25, 20.91it/s]\u001b[A\n",
      " 33%|███▎      | 261/786 [00:11<00:27, 19.35it/s]\u001b[A\n",
      " 34%|███▎      | 264/786 [00:11<00:28, 18.50it/s]\u001b[A\n",
      " 34%|███▍      | 266/786 [00:11<00:27, 18.68it/s]\u001b[A\n",
      " 34%|███▍      | 269/786 [00:12<00:25, 20.45it/s]\u001b[A\n",
      " 35%|███▍      | 272/786 [00:12<00:23, 21.78it/s]\u001b[A\n",
      " 35%|███▍      | 275/786 [00:12<00:25, 20.31it/s]\u001b[A\n",
      " 35%|███▌      | 278/786 [00:12<00:23, 21.66it/s]\u001b[A\n",
      " 36%|███▌      | 281/786 [00:12<00:22, 22.59it/s]\u001b[A\n",
      " 36%|███▌      | 284/786 [00:12<00:24, 20.81it/s]\u001b[A\n",
      " 37%|███▋      | 287/786 [00:12<00:22, 21.98it/s]\u001b[A\n",
      " 37%|███▋      | 290/786 [00:13<00:24, 20.38it/s]\u001b[A\n",
      " 37%|███▋      | 293/786 [00:13<00:22, 21.67it/s]\u001b[A\n",
      " 38%|███▊      | 296/786 [00:13<00:21, 22.72it/s]\u001b[A\n",
      " 38%|███▊      | 299/786 [00:13<00:23, 20.98it/s]\u001b[A\n",
      " 38%|███▊      | 302/786 [00:13<00:21, 22.28it/s]\u001b[A\n",
      " 39%|███▉      | 305/786 [00:13<00:20, 23.29it/s]\u001b[A\n",
      " 39%|███▉      | 308/786 [00:13<00:22, 21.33it/s]\u001b[A\n",
      " 40%|███▉      | 311/786 [00:13<00:21, 22.51it/s]\u001b[A\n",
      " 40%|███▉      | 314/786 [00:14<00:20, 23.41it/s]\u001b[A\n",
      " 40%|████      | 317/786 [00:14<00:21, 21.38it/s]\u001b[A\n",
      " 41%|████      | 320/786 [00:14<00:20, 22.60it/s]\u001b[A\n",
      " 41%|████      | 323/786 [00:14<00:19, 23.51it/s]\u001b[A\n",
      " 41%|████▏     | 326/786 [00:14<00:21, 21.60it/s]\u001b[A\n",
      " 42%|████▏     | 329/786 [00:14<00:19, 22.85it/s]\u001b[A\n",
      " 42%|████▏     | 332/786 [00:14<00:19, 23.79it/s]\u001b[A\n",
      " 43%|████▎     | 335/786 [00:15<00:20, 21.69it/s]\u001b[A\n",
      " 43%|████▎     | 338/786 [00:15<00:19, 22.86it/s]\u001b[A\n",
      " 43%|████▎     | 341/786 [00:15<00:18, 23.74it/s]\u001b[A\n",
      " 44%|████▍     | 344/786 [00:15<00:18, 24.47it/s]\u001b[A\n",
      " 44%|████▍     | 347/786 [00:15<00:19, 22.10it/s]\u001b[A\n",
      " 45%|████▍     | 350/786 [00:15<00:18, 23.23it/s]\u001b[A\n",
      " 45%|████▍     | 353/786 [00:15<00:17, 24.12it/s]\u001b[A\n",
      " 45%|████▌     | 356/786 [00:15<00:19, 21.84it/s]\u001b[A\n",
      " 46%|████▌     | 359/786 [00:16<00:18, 22.98it/s]\u001b[A\n",
      " 46%|████▌     | 362/786 [00:16<00:17, 23.81it/s]\u001b[A\n",
      " 46%|████▋     | 365/786 [00:16<00:19, 21.53it/s]\u001b[A\n",
      " 47%|████▋     | 368/786 [00:16<00:18, 22.64it/s]\u001b[A\n",
      " 47%|████▋     | 371/786 [00:16<00:17, 23.53it/s]\u001b[A\n",
      " 48%|████▊     | 374/786 [00:16<00:19, 21.49it/s]\u001b[A\n",
      " 48%|████▊     | 377/786 [00:16<00:18, 22.65it/s]\u001b[A\n",
      " 48%|████▊     | 380/786 [00:16<00:17, 23.50it/s]\u001b[A\n",
      " 49%|████▊     | 383/786 [00:17<00:19, 21.07it/s]\u001b[A\n",
      " 49%|████▉     | 386/786 [00:17<00:18, 22.01it/s]\u001b[A\n",
      " 49%|████▉     | 389/786 [00:17<00:19, 20.00it/s]\u001b[A\n",
      " 50%|████▉     | 392/786 [00:17<00:20, 18.82it/s]\u001b[A\n",
      " 50%|█████     | 394/786 [00:17<00:20, 19.04it/s]\u001b[A\n",
      " 50%|█████     | 396/786 [00:17<00:20, 19.20it/s]\u001b[A\n",
      " 51%|█████     | 398/786 [00:17<00:20, 19.31it/s]\u001b[A\n",
      " 51%|█████     | 400/786 [00:18<00:19, 19.38it/s]\u001b[A\n",
      " 51%|█████▏    | 403/786 [00:18<00:18, 21.12it/s]\u001b[A\n",
      " 52%|█████▏    | 406/786 [00:18<00:16, 22.43it/s]\u001b[A\n",
      " 52%|█████▏    | 409/786 [00:18<00:18, 20.68it/s]\u001b[A\n",
      " 52%|█████▏    | 412/786 [00:18<00:16, 22.04it/s]\u001b[A\n",
      " 53%|█████▎    | 415/786 [00:18<00:16, 23.05it/s]\u001b[A\n",
      " 53%|█████▎    | 418/786 [00:18<00:17, 21.11it/s]\u001b[A\n",
      " 54%|█████▎    | 421/786 [00:18<00:16, 22.30it/s]\u001b[A\n",
      " 54%|█████▍    | 424/786 [00:19<00:17, 20.66it/s]\u001b[A\n",
      " 54%|█████▍    | 427/786 [00:19<00:16, 21.90it/s]\u001b[A\n",
      " 55%|█████▍    | 430/786 [00:19<00:15, 22.91it/s]\u001b[A\n",
      " 55%|█████▌    | 433/786 [00:19<00:16, 21.05it/s]\u001b[A\n",
      " 55%|█████▌    | 436/786 [00:19<00:15, 22.18it/s]\u001b[A\n",
      " 56%|█████▌    | 439/786 [00:19<00:15, 23.06it/s]\u001b[A\n",
      " 56%|█████▌    | 442/786 [00:19<00:16, 21.13it/s]\u001b[A\n",
      " 57%|█████▋    | 445/786 [00:20<00:15, 22.43it/s]\u001b[A\n",
      " 57%|█████▋    | 448/786 [00:20<00:14, 23.35it/s]\u001b[A\n",
      " 57%|█████▋    | 451/786 [00:20<00:15, 21.25it/s]\u001b[A\n",
      " 58%|█████▊    | 454/786 [00:20<00:14, 22.31it/s]\u001b[A\n",
      " 58%|█████▊    | 457/786 [00:20<00:15, 20.63it/s]\u001b[A\n",
      " 59%|█████▊    | 460/786 [00:20<00:14, 21.84it/s]\u001b[A\n",
      " 59%|█████▉    | 463/786 [00:20<00:14, 22.92it/s]\u001b[A\n",
      " 59%|█████▉    | 466/786 [00:21<00:15, 21.16it/s]\u001b[A\n",
      " 60%|█████▉    | 469/786 [00:21<00:14, 22.35it/s]\u001b[A\n",
      " 60%|██████    | 472/786 [00:21<00:13, 23.26it/s]\u001b[A\n",
      " 60%|██████    | 475/786 [00:21<00:14, 21.34it/s]\u001b[A\n",
      " 61%|██████    | 478/786 [00:21<00:13, 22.54it/s]\u001b[A\n",
      " 61%|██████    | 481/786 [00:21<00:12, 23.51it/s]\u001b[A\n",
      " 62%|██████▏   | 484/786 [00:21<00:14, 21.50it/s]\u001b[A\n",
      " 62%|██████▏   | 487/786 [00:21<00:13, 22.67it/s]\u001b[A\n",
      " 62%|██████▏   | 490/786 [00:22<00:12, 23.63it/s]\u001b[A\n",
      " 63%|██████▎   | 493/786 [00:22<00:13, 21.48it/s]\u001b[A\n",
      " 63%|██████▎   | 496/786 [00:22<00:12, 22.64it/s]\u001b[A\n",
      " 63%|██████▎   | 499/786 [00:22<00:12, 23.57it/s]\u001b[A\n",
      " 64%|██████▍   | 502/786 [00:22<00:13, 21.53it/s]\u001b[A\n",
      " 64%|██████▍   | 505/786 [00:22<00:12, 22.67it/s]\u001b[A\n",
      " 65%|██████▍   | 508/786 [00:22<00:11, 23.70it/s]\u001b[A\n",
      " 65%|██████▌   | 511/786 [00:23<00:12, 21.45it/s]\u001b[A\n",
      " 65%|██████▌   | 514/786 [00:23<00:12, 22.43it/s]\u001b[A\n",
      " 66%|██████▌   | 517/786 [00:23<00:13, 20.35it/s]\u001b[A\n",
      " 66%|██████▌   | 520/786 [00:23<00:12, 21.39it/s]\u001b[A\n",
      " 67%|██████▋   | 523/786 [00:23<00:13, 19.73it/s]\u001b[A\n",
      " 67%|██████▋   | 526/786 [00:23<00:12, 20.94it/s]\u001b[A\n",
      " 67%|██████▋   | 529/786 [00:23<00:13, 19.45it/s]\u001b[A\n",
      " 68%|██████▊   | 532/786 [00:24<00:12, 21.00it/s]\u001b[A\n",
      " 68%|██████▊   | 535/786 [00:24<00:11, 22.26it/s]\u001b[A\n",
      " 68%|██████▊   | 538/786 [00:24<00:11, 20.79it/s]\u001b[A\n",
      " 69%|██████▉   | 541/786 [00:24<00:11, 22.26it/s]\u001b[A\n",
      " 69%|██████▉   | 544/786 [00:24<00:10, 23.38it/s]\u001b[A\n",
      " 70%|██████▉   | 547/786 [00:24<00:09, 24.29it/s]\u001b[A\n",
      " 70%|██████▉   | 550/786 [00:24<00:10, 22.08it/s]\u001b[A\n",
      " 70%|███████   | 553/786 [00:24<00:10, 23.25it/s]\u001b[A\n",
      " 71%|███████   | 556/786 [00:25<00:09, 24.18it/s]\u001b[A\n",
      " 71%|███████   | 559/786 [00:25<00:10, 22.00it/s]\u001b[A\n",
      " 72%|███████▏  | 562/786 [00:25<00:09, 23.15it/s]\u001b[A\n",
      " 72%|███████▏  | 565/786 [00:25<00:09, 24.09it/s]\u001b[A\n",
      " 72%|███████▏  | 568/786 [00:25<00:08, 24.79it/s]\u001b[A\n",
      " 73%|███████▎  | 571/786 [00:25<00:09, 22.35it/s]\u001b[A\n",
      " 73%|███████▎  | 574/786 [00:25<00:09, 23.46it/s]\u001b[A\n",
      " 73%|███████▎  | 577/786 [00:25<00:08, 24.30it/s]\u001b[A\n",
      " 74%|███████▍  | 580/786 [00:26<00:08, 24.92it/s]\u001b[A\n",
      " 74%|███████▍  | 583/786 [00:26<00:09, 22.30it/s]\u001b[A\n",
      " 75%|███████▍  | 586/786 [00:26<00:08, 23.30it/s]\u001b[A\n",
      " 75%|███████▍  | 589/786 [00:26<00:08, 24.05it/s]\u001b[A\n",
      " 75%|███████▌  | 592/786 [00:26<00:08, 21.79it/s]\u001b[A\n",
      " 76%|███████▌  | 595/786 [00:26<00:08, 22.91it/s]\u001b[A\n",
      " 76%|███████▌  | 598/786 [00:26<00:07, 23.80it/s]\u001b[A\n",
      " 76%|███████▋  | 601/786 [00:27<00:08, 21.69it/s]\u001b[A\n",
      " 77%|███████▋  | 604/786 [00:27<00:07, 22.79it/s]\u001b[A\n",
      " 77%|███████▋  | 607/786 [00:27<00:07, 23.81it/s]\u001b[A\n",
      " 78%|███████▊  | 610/786 [00:27<00:08, 21.64it/s]\u001b[A\n",
      " 78%|███████▊  | 613/786 [00:27<00:07, 22.96it/s]\u001b[A\n",
      " 78%|███████▊  | 616/786 [00:27<00:07, 24.00it/s]\u001b[A\n",
      " 79%|███████▉  | 619/786 [00:27<00:06, 24.80it/s]\u001b[A\n",
      " 79%|███████▉  | 622/786 [00:27<00:07, 22.33it/s]\u001b[A\n",
      " 80%|███████▉  | 625/786 [00:28<00:06, 23.25it/s]\u001b[A\n",
      " 80%|███████▉  | 628/786 [00:28<00:06, 23.63it/s]\u001b[A\n",
      " 80%|████████  | 631/786 [00:28<00:07, 21.56it/s]\u001b[A\n",
      " 81%|████████  | 634/786 [00:28<00:06, 22.74it/s]\u001b[A\n",
      " 81%|████████  | 637/786 [00:28<00:06, 23.66it/s]\u001b[A\n",
      " 81%|████████▏ | 640/786 [00:28<00:06, 21.59it/s]\u001b[A\n",
      " 82%|████████▏ | 643/786 [00:28<00:06, 22.72it/s]\u001b[A\n",
      " 82%|████████▏ | 646/786 [00:28<00:05, 23.67it/s]\u001b[A\n",
      " 83%|████████▎ | 649/786 [00:29<00:06, 21.19it/s]\u001b[A\n",
      " 83%|████████▎ | 652/786 [00:29<00:06, 22.16it/s]\u001b[A\n",
      " 83%|████████▎ | 655/786 [00:29<00:06, 20.14it/s]\u001b[A\n",
      " 84%|████████▎ | 658/786 [00:29<00:06, 21.24it/s]\u001b[A\n",
      " 84%|████████▍ | 661/786 [00:29<00:06, 19.61it/s]\u001b[A\n",
      " 84%|████████▍ | 664/786 [00:29<00:05, 20.88it/s]\u001b[A\n",
      " 85%|████████▍ | 667/786 [00:30<00:06, 19.66it/s]\u001b[A\n",
      " 85%|████████▌ | 670/786 [00:30<00:05, 21.01it/s]\u001b[A\n",
      " 86%|████████▌ | 673/786 [00:30<00:05, 19.51it/s]\u001b[A\n",
      " 86%|████████▌ | 676/786 [00:30<00:05, 21.04it/s]\u001b[A\n",
      " 86%|████████▋ | 679/786 [00:30<00:04, 22.27it/s]\u001b[A\n",
      " 87%|████████▋ | 682/786 [00:30<00:05, 20.78it/s]\u001b[A\n",
      " 87%|████████▋ | 685/786 [00:30<00:04, 22.12it/s]\u001b[A\n",
      " 88%|████████▊ | 688/786 [00:30<00:04, 23.11it/s]\u001b[A\n",
      " 88%|████████▊ | 691/786 [00:31<00:04, 21.16it/s]\u001b[A\n",
      " 88%|████████▊ | 694/786 [00:31<00:04, 22.33it/s]\u001b[A\n",
      " 89%|████████▊ | 697/786 [00:31<00:03, 23.37it/s]\u001b[A\n",
      " 89%|████████▉ | 700/786 [00:31<00:04, 21.36it/s]\u001b[A\n",
      " 89%|████████▉ | 703/786 [00:31<00:03, 22.54it/s]\u001b[A\n",
      " 90%|████████▉ | 706/786 [00:31<00:03, 23.42it/s]\u001b[A\n",
      " 90%|█████████ | 709/786 [00:31<00:03, 21.40it/s]\u001b[A\n",
      " 91%|█████████ | 712/786 [00:32<00:03, 22.54it/s]\u001b[A\n",
      " 91%|█████████ | 715/786 [00:32<00:03, 20.82it/s]\u001b[A\n",
      " 91%|█████████▏| 718/786 [00:32<00:03, 22.05it/s]\u001b[A\n",
      " 92%|█████████▏| 721/786 [00:32<00:02, 23.07it/s]\u001b[A\n",
      " 92%|█████████▏| 724/786 [00:32<00:02, 21.28it/s]\u001b[A\n",
      " 92%|█████████▏| 727/786 [00:32<00:02, 22.63it/s]\u001b[A\n",
      " 93%|█████████▎| 730/786 [00:32<00:02, 23.73it/s]\u001b[A\n",
      " 93%|█████████▎| 733/786 [00:32<00:02, 24.51it/s]\u001b[A\n",
      " 94%|█████████▎| 736/786 [00:33<00:02, 22.21it/s]\u001b[A\n",
      " 94%|█████████▍| 739/786 [00:33<00:02, 23.28it/s]\u001b[A\n",
      " 94%|█████████▍| 742/786 [00:33<00:01, 24.04it/s]\u001b[A\n",
      " 95%|█████████▍| 745/786 [00:33<00:01, 21.89it/s]\u001b[A\n",
      " 95%|█████████▌| 748/786 [00:33<00:01, 23.05it/s]\u001b[A\n",
      " 96%|█████████▌| 751/786 [00:33<00:01, 23.85it/s]\u001b[A\n",
      " 96%|█████████▌| 754/786 [00:33<00:01, 24.45it/s]\u001b[A\n",
      " 96%|█████████▋| 757/786 [00:34<00:01, 22.07it/s]\u001b[A\n",
      " 97%|█████████▋| 760/786 [00:34<00:01, 23.12it/s]\u001b[A\n",
      " 97%|█████████▋| 763/786 [00:34<00:00, 23.89it/s]\u001b[A\n",
      " 97%|█████████▋| 766/786 [00:34<00:00, 21.68it/s]\u001b[A\n",
      " 98%|█████████▊| 769/786 [00:34<00:00, 22.84it/s]\u001b[A\n",
      " 98%|█████████▊| 772/786 [00:34<00:00, 23.64it/s]\u001b[A\n",
      " 99%|█████████▊| 775/786 [00:34<00:00, 21.54it/s]\u001b[A\n",
      " 99%|█████████▉| 778/786 [00:34<00:00, 22.73it/s]\u001b[A\n",
      " 99%|█████████▉| 781/786 [00:35<00:00, 23.65it/s]\u001b[A\n",
      "100%|██████████| 786/786 [00:35<00:00, 22.30it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AUROC_micro': np.float64(0.5756615752444324),\n",
       " 'AUROC_macro': np.float64(0.5055387889880079),\n",
       " 'AUROC_weighted': np.float64(0.5092737539366827)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_auc(model.model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20240c08-888b-4c5e-a150-57e476d83c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mimic3-sand",
   "language": "python",
   "name": "mimic3-sand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
